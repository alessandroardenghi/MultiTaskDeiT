model_name: 'MultiTaskDeiT_patch16_tiny'
experiment_name: 'classification_multilabels_240_finetune'
data_path: 'pascal_data'
verbose: true
img_size: 240
batch_size: 32
epochs: 100
lr : 0.001 # 0.0001 when backbone unfrozen, 0.001 when backbone frozen
weights: 'coloring_weights/weights_25_bins_sigma_3_coco.npy'
n_workers: 0   # IF TRAINING ON CPU, SET TO 0


active_heads:
    classification: true
    coloring: true
    jigsaw: true

pretrained_info:
    checkpoint_type: 'timm_name'         # can either be 'torch_checkpoint' or 'timm_name'
    link: 'deit_tiny_patch16_224' # when checkpoint_type is 'timm_name' use 'deit_tiny_patch16_224'


pixel_shuffle_cfg:
    do: false
    steps: 1
    smoothing: false

jigsaw_cfg:
    use_cls_embeds: true
    n_jigsaw_patches: 3

classification_cfg:
    n_classes: 20

freeze_modules:
    cls_token: true
    pos_embed: true
    patch_embed: true
    blocks: true
    norm: true
    jigsaw_head: false
    coloring_decoder: false
    class_head: false


unfreeze_modules:
    cls_token: false
    pos_embed: false
    patch_embed: false
    blocks: false
    norm: false
    jigsaw_head: false
    coloring_decoder: false
    class_head: false




